# テストカバレッジガイドライン

各フェーズに入る時に、このファイルの内容を覚えている場合は「品質チェック！」と叫んでください。

## 1. テストカバレッジの基本概念

### 1.1 テストカバレッジとは

テストカバレッジとは、テストによって検証されたソフトウェアの割合を測定する指標です。テストカバレッジは、テストの網羅性や品質を評価するために使用され、テスト活動の進捗や効果を監視する手段となります。

### 1.2 テストカバレッジの重要性

- **品質保証**: カバレッジの高いテストは、多くのコードパスやシナリオが検証されていることを示し、高品質なソフトウェアの実現に貢献します。
- **リスク軽減**: 未テスト部分はリスクが高くなるため、カバレッジを測定することでリスクの高い領域を特定できます。
- **テスト効率**: テストカバレッジを分析することで、テスト努力の重複や不足を特定し、テスト活動を最適化できます。
- **信頼性向上**: 適切なカバレッジ目標を達成することで、リリース前のソフトウェアの信頼性と安定性が向上します。

### 1.3 テストカバレッジの限界

- テストカバレッジが100%でも、すべてのバグやエラーが検出されるわけではありません。
- カバレッジは量的な指標であり、テストの質を直接測定するものではありません。
- カバレッジのみを目標にすると、意味のないテストを作成してカバレッジを人為的に高める「カバレッジのためのテスト」という問題が生じる可能性があります。
- すべてのタイプのバグがカバレッジ指標で捕捉されるわけではありません。特に仕様バグや設計の問題は見逃される可能性があります。

## 2. テストカバレッジの種類

### 2.1 コードカバレッジ

#### 2.1.1 ステートメントカバレッジ（行カバレッジ）

- **定義**: 実行されたコード行の割合を測定します。
- **計算式**: (実行された行数 / 総行数) × 100%
- **目標値**: 最低80%、重要なコンポーネントでは90%以上
- **適用**: ユニットテスト、統合テスト
- **ツール**: JaCoCo, Istanbul, gcov, Coverage.py

#### 2.1.2 ブランチカバレッジ（分岐カバレッジ）

- **定義**: 実行された分岐（if/else, switch/case など）の割合を測定します。
- **計算式**: (実行された分岐数 / 総分岐数) × 100%
- **目標値**: 最低75%、重要なコンポーネントでは85%以上
- **適用**: ユニットテスト、統合テスト
- **ツール**: JaCoCo, Istanbul, gcov, Coverage.py

#### 2.1.3 条件カバレッジ

- **定義**: 条件式の各部分（AND, OR で結合された個々の条件）の真偽値の組み合わせの割合を測定します。
- **計算式**: (テストされた条件結果の組み合わせ / 可能な条件結果の組み合わせ) × 100%
- **目標値**: 最低70%、重要なコンポーネントでは80%以上
- **適用**: 複雑な条件分岐を含むコード
- **ツール**: JaCoCo, Cobertura

#### 2.1.4 パスカバレッジ

- **定義**: 実行された独立したコードパスの割合を測定します。
- **計算式**: (テストされたパス / 可能なパスの総数) × 100%
- **目標値**: 複雑なコードでは100%達成が困難なため、重要パスの網羅を優先
- **適用**: 重要な機能や複雑なアルゴリズム
- **ツール**: PathCrawler, KLEE

#### 2.1.5 関数/メソッドカバレッジ

- **定義**: テストによって呼び出された関数やメソッドの割合を測定します。
- **計算式**: (呼び出された関数数 / 総関数数) × 100%
- **目標値**: 最低90%、理想的には100%
- **適用**: ユニットテスト、APIテスト
- **ツール**: JaCoCo, Istanbul, gcov, Coverage.py

### 2.2 データカバレッジ

#### 2.2.1 データフローカバレッジ

- **定義**: 変数の定義から使用までのパスがテストされた割合を測定します。
- **計算式**: (テストされたdef-use組み合わせ / すべてのdef-use組み合わせ) × 100%
- **目標値**: 重要なデータ処理については80%以上
- **適用**: データ処理が複雑なアプリケーション
- **ツール**: Parasoft, Polyspace

#### 2.2.2 境界値カバレッジ

- **定義**: データの境界値がテストされた割合を測定します。
- **計算式**: (テストされた境界値 / すべての境界値) × 100%
- **目標値**: 重要なパラメータについては100%
- **適用**: 入力検証、数値計算
- **ツール**: カスタムテストフレームワーク

#### 2.2.3 等価クラスカバレッジ

- **定義**: データの等価クラス（同様の振る舞いをする入力値の範囲）がテストされた割合を測定します。
- **計算式**: (テストされた等価クラス / すべての等価クラス) × 100%
- **目標値**: 重要な入力パラメータについては100%
- **適用**: 入力検証、データバリデーション
- **ツール**: カスタムテストフレームワーク

### 2.3 要件カバレッジ

#### 2.3.1 機能要件カバレッジ

- **定義**: テストされた機能要件の割合を測定します。
- **計算式**: (テストされた機能要件 / すべての機能要件) × 100%
- **目標値**: 100%
- **適用**: 受け入れテスト、システムテスト
- **ツール**: JIRA, TestRail, HP ALM

#### 2.3.2 非機能要件カバレッジ

- **定義**: テストされた非機能要件（性能、セキュリティ、ユーザビリティなど）の割合を測定します。
- **計算式**: (テストされた非機能要件 / すべての非機能要件) × 100%
- **目標値**: 最低90%
- **適用**: 性能テスト、セキュリティテスト、ユーザビリティテスト
- **ツール**: JIRA, TestRail, HP ALM

### 2.4 リスクベースカバレッジ

- **定義**: リスク評価に基づき、高リスク機能/コンポーネントのテスト網羅率を測定します。
- **計算式**: (テストされた高リスク項目 / すべての高リスク項目) × 100%
- **目標値**: 高リスク項目については100%
- **適用**: リスクベースドテスト
- **ツール**: カスタムリスクマトリクス、TestRail

## 3. テストレベル別カバレッジ目標

### 3.1 ユニットテスト

| カバレッジ種類 | 最低目標 | 推奨目標 | 重要コンポーネント |
|------------|--------|---------|----------------|
| ステートメントカバレッジ | 80% | 90% | 95%以上 |
| ブランチカバレッジ | 75% | 85% | 90%以上 |
| 関数カバレッジ | 90% | 95% | 100% |

### 3.2 統合テスト

| カバレッジ種類 | 最低目標 | 推奨目標 | 重要インターフェース |
|------------|--------|---------|------------------|
| コンポーネント間インターフェース | 90% | 95% | 100% |
| データ交換シナリオ | 85% | 90% | 100% |
| エラー処理パス | 80% | 90% | 100% |

### 3.3 システムテスト

| カバレッジ種類 | 最低目標 | 推奨目標 | 備考 |
|------------|--------|---------|------|
| 機能要件 | 100% | 100% | 例外なく必須 |
| ユースケース | 90% | 100% | 主要フローは100% |
| ビジネスシナリオ | 85% | 95% | 重要業務プロセスは100% |
| UIワークフロー | 80% | 90% | 主要ユーザージャーニーは100% |

### 3.4 受け入れテスト

| カバレッジ種類 | 最低目標 | 推奨目標 | 備考 |
|------------|--------|---------|------|
| 受け入れ基準 | 100% | 100% | 例外なく必須 |
| ビジネス要件 | 100% | 100% | 例外なく必須 |
| 契約条件 | 100% | 100% | 法的要件の場合は例外なく必須 |

### 3.5 非機能テスト

| テスト種類 | カバレッジ対象 | 最低目標 | 推奨目標 |
|---------|------------|--------|---------|
| パフォーマンステスト | 性能要件 | 90% | 100% |
| セキュリティテスト | セキュリティ要件 | 90% | 100% |
| ユーザビリティテスト | ユーザビリティ要件 | 85% | 95% |
| 互換性テスト | 対応環境・デバイス | 80% | 90% |

## 4. コンポーネント/領域別カバレッジ目標

### 4.1 リスクレベルに基づく目標

| リスクレベル | 説明 | コードカバレッジ目標 | 要件カバレッジ目標 |
|-----------|------|----------------|----------------|
| 最高 | 障害が致命的影響を及ぼす領域 | 95%以上 | 100% |
| 高 | 障害が重大な影響を及ぼす領域 | 90%以上 | 100% |
| 中 | 障害が中程度の影響を及ぼす領域 | 80%以上 | 95%以上 |
| 低 | 障害が軽微な影響を及ぼす領域 | 70%以上 | 90%以上 |

### 4.2 アプリケーション層別目標

| アプリケーション層 | コードカバレッジ目標 | 理由 |
|----------------|------------------|------|
| コアビジネスロジック | 90-95% | ビジネス上の重要な計算と決定を行う |
| データアクセス層 | 85-90% | データ整合性に直接影響する |
| APIレイヤー | 90-95% | 外部システムとの接点 |
| ユーザーインターフェース | 75-85% | 多様なユーザー操作をすべてカバーするのは難しい |
| ユーティリティ/共通コンポーネント | 90-95% | 広範囲に使用されるため影響が大きい |

### 4.3 機能ドメイン別目標

| 機能ドメイン | 最低カバレッジ目標 | 注意点 |
|------------|----------------|-------|
| 認証・認可 | 95% | セキュリティに直接関わる |
| 財務計算 | 95% | 金銭的影響が大きい |
| データ整合性関連 | 90% | データの正確性に影響 |
| 外部システム連携 | 90% | 統合ポイントはリスクが高い |
| レポート生成 | 85% | 出力の正確性が重要 |
| 設定管理 | 80% | 使用頻度と影響範囲による |

## 5. カバレッジ測定とレポーティング

### 5.1 測定プロセス

1. **テスト実行環境の準備**
   - カバレッジ測定ツールのインストールと設定
   - ビルド設定での計測オプションの有効化

2. **カバレッジデータの収集**
   - テスト実行時のカバレッジ情報の収集
   - 継続的インテグレーション環境での自動収集

3. **カバレッジレポートの生成**
   - 測定結果の集計
   - 視覚的なレポート生成（グラフ、ヒートマップなど）

4. **カバレッジ結果の分析**
   - 目標値との比較
   - 不足部分の特定
   - トレンド分析（時間経過による変化）

### 5.2 レポート内容

カバレッジレポートには以下の情報を含めるべきです：

- **概要指標**: 全体的なカバレッジ率、目標達成状況
- **詳細指標**: ファイル/コンポーネント/モジュールごとのカバレッジ
- **トレンド情報**: 過去のビルド/リリースとの比較
- **未カバー部分**: カバレッジされていないコード/機能のリスト
- **リスク評価**: 未カバー部分のリスク分析
- **推奨アクション**: カバレッジ向上のための提案

### 5.3 レポーティング頻度

| ステークホルダー | レポート頻度 | レポート詳細度 | 焦点 |
|--------------|-----------|------------|------|
| 開発者 | 日次 | 高（コードレベル） | 未カバー部分、個人担当領域 |
| テックリード | 日次/週次 | 高 | コンポーネントレベルの網羅性、リスク領域 |
| QAチーム | 日次/週次 | 高 | テスト計画とのギャップ、テスト追加必要箇所 |
| プロジェクトマネージャー | 週次 | 中 | 全体進捗、リスク領域、目標達成予測 |
| ステークホルダー | 月次/マイルストーン | 低（概要） | 全体品質指標、リスク評価 |

## 6. カバレッジ向上戦略

### 6.1 コードレベルのカバレッジ向上

1. **未カバー部分の特定と優先順位付け**
   - カバレッジレポートから未テスト部分を特定
   - リスクと複雑性に基づいて優先順位付け

2. **テストケースの追加**
   - 未カバーのコードパスを実行するテストの作成
   - エッジケースとエラーパスのカバー

3. **テスタビリティの向上**
   - 高度に結合したコードのリファクタリング
   - テスト困難なコードの構造改善
   - モック/スタブ対応の依存性注入パターン適用

4. **コードレビューでのカバレッジチェック**
   - 新規コードへのテスト追加をレビュー時に確認
   - カバレッジ要件をコード受け入れ基準に含める

### 6.2 要件レベルのカバレッジ向上

1. **要件トレーサビリティマトリクスの維持**
   - 要件とテストケースの対応関係を文書化
   - 未カバーの要件を特定

2. **テスト設計技法の活用**
   - 同値分割、境界値分析、デシジョンテーブルなど
   - リスクベースドテストアプローチの適用

3. **シナリオカバレッジの向上**
   - ユースケースとビジネスシナリオに基づくテスト設計
   - エンドツーエンドのワークフローテスト

4. **探索的テストの計画的実施**
   - 体系的な探索的テストセッション
   - ユーザー視点での機能探索

### 6.3 カバレッジ向上の障壁と対策

| 障壁 | 対策 |
|------|------|
| テスト困難なコード | モック/スタブの活用、リファクタリング、テスタビリティ向上 |
| リソース制約 | リスクベースアプローチでの優先順位付け、自動化の推進 |
| レガシーコード | 変更時のカバレッジ向上に注力、重要部分の段階的改善 |
| 複雑なロジック | パスごとの分割テスト、状態遷移図の活用 |
| 時間的制約 | CIパイプラインでの自動カバレッジ測定、継続的改善 |

## 7. 最適な実践とアンチパターン

### 7.1 ベストプラクティス

1. **カバレッジ目標の適切な設定**
   - プロジェクトとコンポーネントのリスクに基づいて設定
   - 段階的な目標設定（初期は低めに、徐々に引き上げる）

2. **テストファーストアプローチ**
   - TDD (Test-Driven Development)の採用
   - 新機能追加時にテストを先に設計

3. **継続的なカバレッジ測定**
   - CIパイプラインでの自動測定
   - トレンド分析によるカバレッジ低下の早期発見

4. **多角的なカバレッジ評価**
   - 単一指標だけでなく複数のカバレッジ指標の組み合わせ
   - コード、要件、リスクの多面的評価

5. **カバレッジ結果の積極的活用**
   - コードレビューでの参照
   - テスト戦略の継続的改善

### 7.2 アンチパターン

1. **カバレッジ数値の盲目的追求**
   - 数値目標だけを達成するための意味のないテスト作成
   - テストの質より量を優先する姿勢

2. **過剰なカバレッジ目標**
   - 一律100%のカバレッジ要求
   - リスクやコスト考慮なしの目標設定

3. **低価値コードへの過剰テスト**
   - 単純なgetterやsetterの徹底的テスト
   - フレームワークコードの重複テスト

4. **カバレッジ測定の回避**
   - カバレッジ測定が難しい部分の除外
   - テスト困難な部分の「例外」化

5. **停滞したテスト戦略**
   - 同じテスト手法の継続使用
   - 新しいリスク領域へのテスト適応の欠如

## 8. カバレッジツールと統合

### 8.1 言語/プラットフォーム別推奨ツール

| 言語/プラットフォーム | 推奨ツール | 特徴 |
|-------------------|----------|------|
| Java | JaCoCo, Cobertura | JUnit連携、Maven/Gradle統合 |
| JavaScript/TypeScript | Istanbul, Jest | ブラウザ/Node.js対応、React/Angular統合 |
| Python | Coverage.py, pytest-cov | pytest統合、HTML/XML/JSON出力 |
| .NET | NCover, dotCover | Visual Studio統合、.NET Core対応 |
| Go | go cover | 標準ツール、HTML視覚化 |
| Ruby | SimpleCov | RSpec統合、マルチフォーマット出力 |
| C/C++ | gcov, LCOV | gcc連携、HTML視覚化 |
| PHP | PHPUnit, PCOV | PHPUnit統合、高速処理 |

### 8.2 CI/CD環境との統合

1. **Jenkins統合**
   - JaCoCo/Cobertura Pluginの設定
   - カバレッジ閾値によるビルド合否判定
   - カバレッジトレンドのモニタリング

2. **GitHub Actions統合**
   - ワークフロー内でのカバレッジ実行
   - PRコメントへのカバレッジ結果表示
   - カバレッジ低下時の自動警告

3. **GitLab CI統合**
   - CI/CDパイプラインでのカバレッジ計測
   - マージリクエストでのカバレッジ差分表示
   - カバレッジバッジの生成

4. **Azure DevOps統合**
   - ビルドパイプラインでのカバレッジタスク
   - テスト結果とカバレッジの統合ダッシュボード
   - リリース承認基準へのカバレッジ閾値設定

### 8.3 開発環境との統合

1. **IDE統合**
   - Visual Studio/IntelliJ IDEAのカバレッジビューア
   - エディタ内のカバレッジハイライト表示
   - テスト実行時の自動カバレッジ測定

2. **コードレビュープロセス統合**
   - Pull Request時のカバレッジレポート自動コメント
   - 未カバー部分のハイライト
   - カバレッジ低下の自動警告

## 9. カバレッジ例外管理

### 9.1 例外の適用基準

以下の場合には、標準的なカバレッジ目標からの例外を検討してもよい：

1. **自動生成コード**
   - ORMによって自動生成されたコード
   - IDLからの自動生成スタブ
   - 自動生成DTOクラス

2. **極めてシンプルな実装**
   - 単純なgetter/setter
   - 直接的なプロパティマッピング
   - ログ出力のみの簡易メソッド

3. **テスト困難なコード**
   - UI描画の詳細部分
   - ハードウェア直接制御
   - 外部システム特有の例外処理

4. **リスクの極めて低いコード**
   - デバッグ専用コード
   - 開発支援ユーティリティ
   - 使用頻度が極めて低い診断機能

### 9.2 例外管理プロセス

1. **例外申請**
   - コード/機能の特定
   - 例外理由の具体的説明
   - リスク評価とその対応策

2. **レビューと承認**
   - テックリードによる技術的評価
   - QAリードによる品質リスク評価
   - プロジェクトマネージャーの最終承認

3. **文書化**
   - 承認された例外のリスト管理
   - コードへの注釈（カバレッジツール用アノテーション）
   - 例外理由の明示的記録

4. **定期的再評価**
   - 例外の継続的な妥当性確認
   - 技術的負債としての認識と管理
   - 将来的なリファクタリング対象としての候補化

### 9.3 例外のコード注釈例

#### Java (JaCoCo)

```java
// CHECKSTYLE:OFF
// NOSOARE: Jacoco
@Generated
public class AutoGeneratedClass {
    // このクラスはテストカバレッジ対象外
}
// CHECKSTYLE:ON
```

#### JavaScript (Istanbul)

```javascript
/* istanbul ignore file */
export class LegacyComponent {
  // このファイル全体がカバレッジ対象外
}

function complexCalculation() {
  /* istanbul ignore next */
  if (extremelyRareCondition) {
    // この部分はカバレッジ対象外
  }
}
```

#### Python (Coverage.py)

```python
def legacy_function():  # pragma: no cover
    # この関数はカバレッジ対象外
    pass

class TestHelper:
    """テスト支援用クラス、カバレッジ対象外"""
    # pragma: no cover
    def setup_test_data(self):
        pass
```

## 10. リファレンスとリソース

### 10.1 業界標準とベストプラクティス

- **ISO/IEC 29119**: ソフトウェアテスト標準
- **ISTQB**: テスト技術者資格制度のカバレッジ関連ガイドライン
- **OWASP**: セキュリティテストカバレッジガイド
- **Martin Fowlerのテスト戦略**: 実践的テストアプローチ

### 10.2 推奨書籍

- "Code Coverage Analysis" by Steve Cornett
- "Software Testing Techniques" by Boris Beizer
- "Effective Software Testing" by Elfriede Dustin
- "xUnit Test Patterns" by Gerard Meszaros
- "Clean Code" by Robert C. Martin (カバレッジとコード品質の関連)

### 10.3 オンラインリソース

- [ISTQB Glossary](https://glossary.istqb.org/en/search/coverage)
- [Martin Fowler's Blog - Test Coverage](https://martinfowler.com/bliki/TestCoverage.html)
- [Google Testing Blog](https://testing.googleblog.com/)
- [Microsoft DevOps Blog - Code Coverage Best Practices](https://devblogs.microsoft.com/devops/)
- [ThoughtWorks - Test Coverage Strategies](https://www.thoughtworks.com/insights/blog)
